# Elasticsearch 深度分页实现方式

本文将介绍几种在 Elasticsearch 中实现深度分页的方法，并分析它们各自的适用场景。

## 1. `from` 和 `size`

这是最基本的分页方式。

*   **实现方式:** 通过设置 `from` 参数（偏移量）和 `size` 参数（每页大小）来获取数据。
*   **适用场景:** 适用于数据量较小，或者用户很少翻到很深页数的场景（例如，常规的 Web 搜索结果）。
*   **缺点:** 性能问题。Elasticsearch 需要在每个分片上检索 `from + size` 条数据，然后将这些数据汇集到协调节点进行排序，最后返回 `size` 条数据。当 `from` 值很大时，会消耗大量内存和 CPU，导致查询缓慢甚至节点崩溃。

## 2. Scroll API

Scroll API 允许我们像在传统数据库中使用游标一样，从 Elasticsearch 中高效地批量检索大量结果。

*   **实现方式:** 第一次请求时包含 `scroll` 参数，后续请求则使用上次返回的 `_scroll_id` 来获取下一批数据。
*   **适用场景:** 需要处理大量数据，例如数据导出、数据迁移或批处理任务。
*   **缺点:**
    *   不适合实时、随机的页面跳转，因为它必须按顺序获取数据。
    *   会占用大量资源来维持一个快照（snapshot），因此不适用于高并发的实时用户请求。
    *   `_scroll_id` 会随着每次请求而改变，需要持续更新。

## 3. `search_after`

`search_after` 提供了一个实时、高效的深度分页解决方案。它通过使用前一页最后一个文档的排序值来获取下一页的数据。

*   **实现方式:** 在查询中指定 `sort` 字段，并在 `search_after` 参数中传入上一页最后一个文档的排序值数组。
*   **适用场景:** 实时、高并发的深度分页场景，例如无限滚动的列表。
*   **缺点:**
    *   不能随机跳转到任意页面，只能是“上一页”或“下一页”。
    *   排序字段的值必须在所有文档中是唯一的，通常需要一个唯一字段（如 `_id`）作为次要排序字段。

## 4. 使用 “bookmarks” 分区法

这是一种基于业务逻辑的应用层分页策略，通过创建特定的“分区”或“书签”来模拟分页。

*   **实现方式:** 在索引时，为文档增加一个或多个用于分区的字段（例如，按时间、ID范围、或者某个聚合值的 hash）。查询时，通过过滤这个分区字段来缩小结果集，然后再在分区内部进行分页。
*   **适用场景:** 超大规模数据集的深度分页，特别是当可以根据业务规则预先定义分区时。适用于需要跳转到特定“区域”而非精确页码的场景。
*   **缺点:**
    *   实现相对复杂，需要预先规划分区策略。
    *   分区的粒度和效果高度依赖于数据分布和业务场景。
    *   如果分区不均匀，可能会导致某些分区的数据量过大。

---

## “Bookmarks” 分区法详细案例

下面我们通过一个具体的场景来演示如何使用 “bookmarks” 分区法。

### 场景设定

假设我们有一个日志系统，收集了来自数百万个物联网设备的日志。每条日志包含设备 ID (`device_id`)、时间戳 (`@timestamp`) 和日志内容 (`message`)。数据量非常庞大，每天有数十亿条新日志。

我们的需求是：能够快速跳转到任意时间点或任意设备产生的大致日志位置，并从此开始向后浏览。例如，“查看6月1日上午10点左右的日志” 或 “查看 device-abc 在最近一周的第5000条到第5010条日志”。

直接使用 `from` 和 `size` 跳转到第几百万页是不现实的。`search_after` 虽然高效，但只能一页一页地翻，无法直接跳到中间的某个位置。

### 解决方案：创建分区字段

我们在索引文档时，增加一个 `partition_id` 字段。这个字段的值由 `@timestamp` 和 `device_id` 计算得来。

一个简单的分区策略是：**按天和设备 ID 的首字母进行分区**。

例如，对于一条时间戳为 `2023-06-01T10:30:00Z`、`device_id` 为 `device-abc` 的日志，我们可以生成一个 `partition_id`：“2023-06-01_d”。

*   `2023-06-01` 是日期部分。
*   `_d` 是 `device_id` 的首字母 `d`。

这样，所有在6月1日产生、且设备 ID 以 'd' 开头的日志，都会被划分到同一个分区。

### 1. 索引映射 (Index Mapping)

首先，定义索引的 mapping，确保 `partition_id` 是一个 `keyword` 类型，以便进行精确过滤。

```json
PUT /iot_logs
{
  "mappings": {
    "properties": {
      "@timestamp": { "type": "date" },
      "device_id": { "type": "keyword" },
      "message": { "type": "text" },
      "partition_id": { "type": "keyword" }
    }
  }
}
```

### 2. 索引数据

在应用程序中，当一条新的日志需要被索引时，我们动态计算 `partition_id` 并一起写入。

```json
POST /iot_logs/_doc
{
  "@timestamp": "2023-06-01T10:30:00Z",
  "device_id": "device-abc-123",
  "message": "Device is online.",
  "partition_id": "2023-06-01_d"
}
```

```json
POST /iot_logs/_doc
{
  "@timestamp": "2023-06-01T11:00:00Z",
  "device_id": "sensor-xyz-456",
  "message": "Temperature reading: 25.5C",
  "partition_id": "2023-06-01_s"
}
```

### 3. 查询与分页

现在，用户的查询可以分为两步：

**第一步：定位到分区。**

用户想查看 “6月1日，设备ID以 'd' 开头的日志”。应用会生成 `partition_id` 为 `2023-06-01_d`。

**第二步：在分区内进行分页。**

在这个分区内部，数据量已经大大减少。我们可以安全地使用 `from` 和 `size` 进行分页，甚至可以翻到很深的页数，因为查询范围已经被 `partition_id` 大大缩小了。

例如，要获取这个分区的第500页，每页10条数据：

```json
GET /iot_logs/_search
{
  "query": {
    "bool": {
      "filter": [
        { "term": { "partition_id": "2023-06-01_d" } }
      ]
    }
  },
  "sort": [
    { "@timestamp": "asc" } 
  ],
  "from": 4990, 
  "size": 10
}
```

这个查询的性能会远高于在全量数据中执行 `from: 4990`。Elasticsearch 只需在 `2023-06-01_d` 这个小得多的数据子集上进行操作。

### 组合使用 `search_after`

为了追求极致性能，我们还可以在分区内部使用 `search_after` 来代替 `from` + `size`。

**获取第一页：**

```json
GET /iot_logs/_search
{
  "query": {
    "term": {
      "partition_id": "2023-06-01_d"
    }
  },
  "sort": [
    { "@timestamp": "asc" },
    { "_id": "asc" } 
  ],
  "size": 10
}
```

假设返回的最后一条文档的 `@timestamp` 是 `1685592000000` (纪元毫秒)，`_id` 是 `Wxyz123`。

**获取下一页：**

```json
GET /iot_logs/_search
{
  "query": {
    "term": {
      "partition_id": "2023-06-01_d"
    }
  },
  "sort": [
    { "@timestamp": "asc" },
    { "_id": "asc" }
  ],
  "size": 10,
  "search_after": [1685592000000, "Wxyz123"] 
}
```

### 总结

“Bookmarks” 分区法将一个大的深度分页问题，分解成了“先定位，再分页”的两个小问题。

*   **优点:**
    *   极大地提高了深度分页的查询性能。
    *   允许用户“跳跃”到数据集的某个大致区域，这是 `search_after` 无法做到的。
    *   分区策略灵活，可以根据业务需求（如按用户、按地区、按时间等）定制。

*   **实施关键:**
    *   设计一个合理的分区策略至关重要。你需要保证分区足够小，以便在分区内分页是高效的；同时也要避免分区过多或过碎，增加管理的复杂性。
    *   分区字段 (`partition_id`) 必须在索引时计算并存入。
